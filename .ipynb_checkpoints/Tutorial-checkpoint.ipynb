{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\"> Relationship Analysis of People’s Income and Restaurants Nearby </p>\n",
    "### <p style=\"text-align: center;\"> Liang Zhang, Shan Li </p>\n",
    "### <p style=\"text-align: center;\"> School of Computer Science, Carnegie Mellon University </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Does local individual income level and other financial information contribute into the success of local restaurants? Where should one run a restaurant business in US? We are going to examine the nationwide data of the popularity of restaurants from Yelp and local individual income and other financial information from Internal Revenue Service, explore the relation of both features within each of them and also features cross these two fields, and try to answer the questions aforementioned. Yelp is a widely used website that provides crowd-sourced reviews about local businesses, and the Internal Revenue Service is the nation's tax collection agency and administers the Internal Revenue Code enacted by Congress.$^{[1]}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Resource\n",
    "### SOI Data from IRS\n",
    "ZIP Code data show selected income and tax items classified by State, ZIP Code, and size of adjusted gross income. Data are based on individual income tax returns filed with the IRS and are available for Tax Years 1998, 2001, and 2004 through 2015. The data include items, such as: number of returns, which approximates the number of households; number of personal exemptions, which approximates the population; adjusted gross income; wages and salaries; dividends before exclusion; interest received and so on$^{[2]}$.\n",
    "\n",
    "In our work, we only employed SOI data for Tax Years 2015, which is the latest recorded one. Also, the SOI data is rich in information which includes tens of thousands of tax-related information. We applied only a small part of this data for our use. More specifically, we only employed \"$\\textit{total income}$\", \"$\\textit{salary}$\", \"$\\textit{business income}$\", \"$\\textit{unemployment compensation}$\", \"$\\textit{pension}$\" and \"$\\textit{capital gain}$\" these six income-related information.\n",
    "### Yelp Data\n",
    "We use both crawler and Yelp Fusion API in this project. \n",
    "\n",
    "For raw crawler, we only retrieved the oldest date of review appear in the website page provided by Yelp.\n",
    "\n",
    "For other basic information of restaurant, we employed Yelp's Fusion API$^{[3]}$ to get thiese feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup library imports\n",
    "import io, time, json\n",
    "import requests\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Crawling and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOI data cleaning\n",
    "* $\\textbf{Inner join related items}$:  \n",
    "The SOI data contains 6 records for each postal code and each records contains all the income-related information that we need. The 6 records are for diffrent level of \"$\\textit{total income}$\" which is one of the attributes it the records. Since we need to use averaged value of all features in one region of a specific postal code, we need to join the 6 records together by adding all income values togeter within one specific postal code.\n",
    "\n",
    "\n",
    "* $\\textbf{Extract 6 income-related feature for each zip code}$:  \n",
    "The SOI data contains 130 features for each record, however, we found that there are only 6 features draw our interest. So we choose these 6 feature subjectively by filtering out all other features.\n",
    "\n",
    "\n",
    "* $\\textbf{Drop any item that lack of any features or has number of returns less than a specified threshold to clean data}$:  \n",
    "The SOI data contains lots of noise that needs to be taken care of such as lack of features, short of number of returns (which make the records) and so on. Basically, we set a threshold of 2500, and we simply drop the entire record in which any feature that has the number of returns less than the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_income_data(filename):\n",
    "    threshold = 1200\n",
    "    dic = {'zip_code': [], 'total_income':[], 'salary':[], 'business_income':[], 'unemployment_compensation':[], 'pension':[], 'capital_gain':[]}\n",
    "    dic_res = {'zip_code': [], 'total_income':[], 'salary':[], 'business_income':[], 'unemployment_compensation':[], 'pension':[], 'capital_gain':[]}\n",
    "    with open(filename, encoding = 'utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            if row['zipcode'] == '99999' or row['zipcode'] == '0':\n",
    "                continue\n",
    "            if len(dic['zip_code']) == 0 or row['zipcode'] != dic['zip_code'][-1]:\n",
    "                if len(dic['zip_code']) != 0 and (dic['total_income'][-1] < threshold or dic['salary'][-1] < threshold or dic['business_income'][-1] < threshold or dic['unemployment_compensation'][-1] < threshold or dic['pension'][-1] < threshold or dic['capital_gain'][-1] < threshold):\n",
    "                    dic['zip_code'][-1] = row['zipcode']\n",
    "                    dic['total_income'][-1] = int(row['N02650'])\n",
    "                    dic['salary'][-1] = int(row['N00200'])\n",
    "                    dic['business_income'][-1] = int(row['N00900'])\n",
    "                    dic['unemployment_compensation'][-1] = int(row['N02300'])\n",
    "                    dic['pension'][-1] = int(row['N01700'])\n",
    "                    dic['capital_gain'][-1] = int(row['N01000'])\n",
    "                    dic_res['zip_code'][-1] = row['zipcode']\n",
    "                    dic_res['total_income'][-1] = int(row['A02650'])\n",
    "                    dic_res['salary'][-1] = int(row['A00200'])\n",
    "                    dic_res['business_income'][-1] = int(row['A00900'])\n",
    "                    dic_res['unemployment_compensation'][-1] = int(row['A02300'])\n",
    "                    dic_res['pension'][-1] = int(row['A01700'])\n",
    "                    dic_res['capital_gain'][-1] = int(row['A01000'])\n",
    "                else:\n",
    "                    dic['zip_code'].append(row['zipcode'])\n",
    "                    dic['total_income'].append(int(row['N02650']))\n",
    "                    dic['salary'].append(int(row['N00200']))\n",
    "                    dic['business_income'].append(int(row['N00900']))\n",
    "                    dic['unemployment_compensation'].append(int(row['N02300']))\n",
    "                    dic['pension'].append(int(row['N01700']))\n",
    "                    dic['capital_gain'].append(int(row['N01000']))\n",
    "                    dic_res['zip_code'].append(row['zipcode'])\n",
    "                    dic_res['total_income'].append(int(row['A02650']))\n",
    "                    dic_res['salary'].append(int(row['A00200']))\n",
    "                    dic_res['business_income'].append(int(row['A00900']))\n",
    "                    dic_res['unemployment_compensation'].append(int(row['A02300']))\n",
    "                    dic_res['pension'].append(int(row['A01700']))\n",
    "                    dic_res['capital_gain'].append(int(row['A01000']))\n",
    "            else:\n",
    "                dic['total_income'][-1] += int(row['N02650'])\n",
    "                dic['salary'][-1] += int(row['N00200'])\n",
    "                dic['business_income'][-1] += int(row['N00900'])\n",
    "                dic['unemployment_compensation'][-1] += int(row['N02300'])\n",
    "                dic['pension'][-1] += int(row['N01700'])\n",
    "                dic['capital_gain'][-1] += int(row['N01000'])\n",
    "                dic_res['total_income'][-1] += int(row['A02650'])\n",
    "                dic_res['salary'][-1] += int(row['A00200'])\n",
    "                dic_res['business_income'][-1] += int(row['A00900'])\n",
    "                dic_res['unemployment_compensation'][-1] += int(row['A02300'])\n",
    "                dic_res['pension'][-1] += int(row['A01700'])\n",
    "                dic_res['capital_gain'][-1] += int(row['A01000'])\n",
    "        if len(dic['zip_code']) != 0 and (dic['total_income'][-1] < threshold or dic['salary'][-1] < threshold or dic['business_income'][-1] < threshold or dic['unemployment_compensation'][-1] < threshold or dic['pension'][-1] < threshold or dic['capital_gain'][-1] < threshold):\n",
    "            dic['zip_code'] = dic['zip_code'][:-1]\n",
    "            dic['total_income'] = dic['total_income'][:-1]\n",
    "            dic['salary'] = dic['salary'][:-1]\n",
    "            dic['business_income'] = dic['business_income'][:-1]\n",
    "            dic['unemployment_compensation'] = dic['unemployment_compensation'][:-1]\n",
    "            dic['pension'] = dic['pension'][:-1]\n",
    "            dic['capital_gain'] = dic['capital_gain'][:-1]\n",
    "            dic_res['zip_code'] = dic_res['zip_code'][:-1]\n",
    "            dic_res['total_income'] = dic_res['total_income'][:-1]\n",
    "            dic_res['salary'] = dic_res['salary'][:-1]\n",
    "            dic_res['business_income'] = dic_res['business_income'][:-1]\n",
    "            dic_res['unemployment_compensation'] = dic_res['unemployment_compensation'][:-1]\n",
    "            dic_res['pension'] = dic_res['pension'][:-1]\n",
    "            dic_res['capital_gain'] = dic_res['capital_gain'][:-1]\n",
    "    return dic_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['99507', '92336', '94112', '95076']\n",
      "4\n",
      "{'zip_code': ['99507', '92336', '94112', '95076'], 'total_income': [19570, 40660, 44190, 37210], 'salary': [17150, 36290, 37490, 32880], 'business_income': [2700, 7380, 8530, 4540], 'unemployment_compensation': [4700, 2620, 2600, 6120], 'pension': [2980, 4700, 5410, 4150], 'capital_gain': [2850, 2510, 5930, 3300]}\n"
     ]
    }
   ],
   "source": [
    "income_dict = preprocess_income_data('15zpallagi.csv')\n",
    "print(income_dict['zip_code'])\n",
    "print(len(income_dict['zip_code']))\n",
    "print(income_dict)\n",
    "\n",
    "# with open('preprocessed_income_data_2015.pickle', 'wb') as file:\n",
    "#     pickle.dump(income_dict, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('preprocessed_income_data_2015.pickle', 'rb') as file:\n",
    "#     income_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the zip code we got from preprocessed SOI data\n",
    "\n",
    "Figure 1 shows the distribution of postal codes we got from our preprocessed SOI data.\n",
    "\n",
    "\n",
    "As is shown, postal codes aggregated around areas that has large citys such as New York City and Carlifornia. Since we filtered out postal codes where there are less people report their income information, it reflects that large cities contains more people that afford tax and the corrsponding income of theese regions are higher than other areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Map_US.jpg\" alt=\"US_MAP\">\n",
    "<p style=\"text-align: center;\">Figure 1. Distributon of our yelp data on US map</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp data crawling and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp data crawling\n",
    "* Using Yelp Fusion API, we got all restaurant basic information including “$\\textit{name}$”, “$\\textit{rating}$”, “$\\textit{review count}$”, “$\\textit{price}$”.\n",
    "* In the previous step, we preprocessed the SOI data and finally got a a list of 8000+ records for each of which we have an unique postal code corresponding to it. In this step, we search via Yelp's API given the list of zipcode so that we cound connect data from SOI data and that from Yelp data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_api_key(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        api_key = f.read().replace('\\n','')\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_restaurants(api_key, zip_code):\n",
    "    # find restaurants established before 2015 according to zip_code\n",
    "    # zip_code: str\n",
    "    offset = 0\n",
    "    headers = {\n",
    "        \"authorization\": 'Bearer %s' % api_key, # for yelp API\n",
    "    }\n",
    "    total_num = 1\n",
    "    dic_list = []\n",
    "    while offset < total_num:\n",
    "        params = {\n",
    "            \"location\": zip_code,\n",
    "            \"categories\": \"restaurant\",\n",
    "            \"offset\": offset,\n",
    "            \"limit\": 50,\n",
    "            \"sort_by\": \"review_count\",\n",
    "        }\n",
    "        result = requests.get('https://api.yelp.com/v3/businesses/search', headers= headers, params=params).json()\n",
    "        if 'businesses' not in result:\n",
    "            break\n",
    "        dic_list += result['businesses']\n",
    "        total_num = result['total']\n",
    "        offset += 50\n",
    "        time.sleep(0.2)\n",
    "    return dic_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_from_yelp(zipcode):\n",
    "    data = all_restaurants(read_api_key('api_key.txt'), zipcode)\n",
    "    \n",
    "    res = []\n",
    "    for data_i in data:\n",
    "        if 'name' not in data_i \\\n",
    "        or 'rating' not in data_i \\\n",
    "        or 'review_count' not in data_i \\\n",
    "        or 'price' not in data_i \\\n",
    "        or 'transactions' not in data_i:\n",
    "            continue\n",
    "\n",
    "        cur_list = [zipcode, data_i['name'], data_i['rating'], data_i['review_count'], data_i['price'], str(data_i['transactions'])]\n",
    "#         print(cur_list)\n",
    "        res.append(cur_list)\n",
    "    print(\"final length is: \", len(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp data preprocessing\n",
    "* $\\textbf{Remove the \"$\\textit{noise restaurants}$\"}$:  \n",
    "Since the SOI data we got from RSI is only for Tax Year 2015, we want to filter all information to the restaurants that happens after 2015. However, can not find a perfect way to do this. For example, we have no information which part of rate to a specific restaurant comes before or after 2015. So we here used a working around solution: when we find a specific restaurant via the Yelp's search, we will go into their website and found the oldest date among all reviews of this restaurant. Next, we simply drop the restaurant if the date is after 2015, and this restaurant was treated as \"$\\textit{noise restaurants}$\". Although it is not a perfect approach, in this way we could slightly reduce the noice of our data dataset.\n",
    "\n",
    "\n",
    "* $\\textbf{Drop restaurants that have any blank attribute basic information above}$:  \n",
    "As a general approach, we simply drop the retrieved restaurants that has any of features we are looking at empty.\n",
    "\n",
    "\n",
    "* $\\textbf{Sort the data by review count}$:  \n",
    "One of the limt of the Yelp Fusion API is it constrains the max number of access of its business to 1000. However, we found that most of the number of restaurants given a specific region is less than 1000. And in order to further reduce the noise of data, we sort the Yelp data by its \"$\\textit{review count}$\" attribute, which means we only retrieve the top 1000 popular restaurants for those regions that has a number of restaurants larger than 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_restaurant_before_2015(url):\n",
    "    \"\"\"\n",
    "    Check whether or not the restaurant established before 2015.\n",
    "\n",
    "    Parameters:\n",
    "        url (string): Yelp URL corresponding to the restaurant of interest.\n",
    "\n",
    "    Returns:\n",
    "        (boolean): whether or not the restaurant established before 2015.\n",
    "    \"\"\"\n",
    "    url += \"&sort_by=date_asc\"\n",
    "    html = requests.get(url).content\n",
    "    url=None\n",
    "    while True:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for div in soup.find_all(\"div\", class_=\"review review--with-sidebar\"):\n",
    "            tmp = re.search(\"[0-9]*/[0-9]*/[0-9]*\", div.find(\"span\", class_='rating-qualifier').get_text())\n",
    "            if tmp is not None:\n",
    "                tmp = tmp.group(0).rstrip()\n",
    "                tmp = (tmp[tmp.rfind('/') + 1:])\n",
    "                try:\n",
    "                    if int(tmp) <= 2015:\n",
    "                        return True\n",
    "                    return False\n",
    "                except:\n",
    "                    continue\n",
    "        url=soup.find(\"a\", class_=\"u-decoration-none next pagination-links_anchor\")\n",
    "        if url is not None:\n",
    "            url=url['href']\n",
    "            html=requests.get(url).content\n",
    "        else:\n",
    "            break\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite database  \n",
    "We use SQLite as our database and store all data in a \"$\\textit{.db}$\" file to manage our crawled data. We commit all changes to our database for each record we crawled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"yelp.db\")\n",
    "cur = con.cursor()\n",
    "cur.execute(\"CREATE TABLE yelp (zipcode TEXT,name TEXT,rating REAL,review_count INT,price TEXT,transactions TEXT)\")\n",
    "\n",
    "with open(\"zipcode.txt\") as f: \n",
    "    zipcode = f.read().splitlines()\n",
    "for i, zc in enumerate(zipcode):\n",
    "    if i <= 458:\n",
    "        continue\n",
    "    print(i)\n",
    "    print(zc)\n",
    "    res = get_data_from_yelp(zc)\n",
    "\n",
    "    cur.executemany(\"INSERT INTO yelp (zipcode,name,rating,review_count,price,transactions) VALUES (?, ?, ?, ?, ?, ?);\", res)\n",
    "    con.commit()\n",
    "con.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Analysis\n",
    "For all following figures that we used to illustrate our work, we use \"$\\textit{RStudio}$\" to plot our figures which is base on R language."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution and Correlation for SOI data\n",
    "We store SOI data into our SQLite database also. To extract SOI data we use the following SQL string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_string = 'CREATE TABLE irs_1 AS\\\n",
    "  SELECT \\\n",
    "  \tSTATE, zipcode, Ntotal_return, Atotal_return/Ntotal_return as Avg_total_return, \\\n",
    "  \tNsalary, Asalary/Nsalary as Avg_salary,\\\n",
    "  \tNbusiness, Abusiness/Nbusiness as Avg_business,\\\n",
    "  \tNunemploy, Aunemploy/Nunemploy as Avg_unemploy,\\\n",
    "  \tNpension, Apension/Npension as Avg_pension,\\\n",
    "  \tNcapital, Acapital/Ncapital as Avg_capital\\\n",
    "  FROM (\\\n",
    "\tSELECT STATE, zipcode, sum(N02650) as Ntotal_return, sum(A02650) as Atotal_return,\\\n",
    "    sum(N00200) as Nsalary, sum(A00200) as Asalary, sum(N00900) as Nbusiness,\\\n",
    "    sum(A00900) as Abusiness, sum(N02300) as Nunemploy, sum(A02300) as Aunemploy,\\\n",
    "    sum(N01700) as Npension, sum(A01700) as Apension, sum(N01000) as Ncapital,\\\n",
    "    sum(A01000) as Acapital FROM irs GROUP BY zipcode\\\n",
    "\t) where Ntotal_return >= 1200 and Nsalary >= 1200 and Nbusiness >= 1200 and Nunemploy >= 1200 and Npension >= 1200 and Ncapital >= 1200;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Distribution for one feature itself in SOI data}$  \n",
    "   In order to visulize the data distribution of SOI data itself, we examined the cumulative distribution for people's total income, as well as other forms of incomes, where salary takes the majority of the total income. Figure 2 shows the overview of distribution of SOI data. There are 6 attributes/featuers we extracted form SOI data, and for each sub-graph in Figure 6, we could see a distribution for one attribute/feature in SOI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Overview of distribution of SOI data.jpg\" alt=\"SOI_data\">\n",
    "<p style=\"text-align: center;\">Figure 2. Overview of distribution of SOI data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Relation for two features in SOI data using Linear Regression}$  \n",
    "   We examined the correlation between average salary and other kind of incomes in SOI data. Therefore we run Linear Regression and pot the figure out in order to visulize the relaton between some pair of features in SOI data. Figure 3 shows these relation below.  \n",
    "   As Figure 3 shows, the business income and average pension are positively related to average salary while Capital gain seems quite independent, which is not surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"SOI.jpg\" alt=\"SOI_relation_data\">\n",
    "<p style=\"text-align: center;\">Figure 3. Linear Relation between features in SOI data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution and Correlation for Yelp data\n",
    "We store Yelp data into our SQLite database. To extract Yelp data we use the following SQL string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_mean_sql_string = 'CREATE TABLE yelp_mean AS\\\n",
    "                        SELECT zipcode, avg(rating) as avg_rating,\\\n",
    "                        avg(review_count) as review_count\\\n",
    "                        FROM yelp\\\n",
    "                        GROUP BY zipcode;'\n",
    "\n",
    "yelp_price_sql_string = 'CREATE TABLE yelp_price AS\\\n",
    "                        SELECT zipcode, avg(price_val) as avgprice\\\n",
    "                        FROM\\\n",
    "                        (SELECT zipcode, length(price) as price_val\\\n",
    "                        FROM yelp)\\\n",
    "                        GROUP BY zipcode;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Distribution for one feature itself in Yelp data}$  \n",
    "   In order to visulize the data distribution of Yelp data itself, we examined the cumulative distribution for each one of three features in Yelp data. Figure 4 shows the overview of distribution of Yelp data.  \n",
    "   From Yelp Data, we can see the average rating is evenly distributed, while over 80% of restuarants has fewer than 200 reviews and the top 2% of them has over a thousand reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Overview of distribution of Yelp data.jpg\" alt=\"Yelp_data\">\n",
    "<p style=\"text-align: center;\">Figure 4. Overview of distribution of Yelp data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Relation for two features in Yelp data using Linear Regression}$  \n",
    "   Figure 5 shows linear relations between any two pairs of features in Yelp data. We do find that the average rating tends to be higher when the price goes up. On the other hand, there are still a bunch of high-rating restaurants with moderate price. The plot on the right side of Figure 5 shows that when there are many reviews for a restuarant, the rating is very likely to be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Yelp.jpg\" alt=\"Yelp_data\">\n",
    "<p style=\"text-align: center;\">Figure 5. Linear Relation between features in Yelp data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between two different data set\n",
    "We also examined and visulized the correlation between SOI and Yelp data set. For SOI data, we only select \"$\\textit{Average Salary}$\" for a region from SOI; for Yelp data, we examined all three features including \"$\\textit{Average Price}$\", \"$\\textit{Averaged Review Count}$\" and \"$\\textit{Averaged Rating}$\".\n",
    "\n",
    "When did this by joining the two tables by the same zipcode. As Figure 6 shows, the correlation between local peoples income and the rating is actually weak. This means the key to a successful restaurant is NOT the wealthiness of the people in this area!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Yelp&SOI.jpg\" alt=\"Yelp_data\">\n",
    "<p style=\"text-align: center;\">Figure 6. Linear Relation between features in SOI and Yelp data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We focused on the relation analysis of data in SOI and Yelp data set. We crawled and preprocessed data from RSI website and Yelp website; visualized the individual data distribution for each data set; explore the correlation of pair of features both within each data set and also cross two data set. Finally we could answer the question that we put forward at the begining: Indeed there are relations between features corresponding to one restaurant like number of reviews and its rating, and also there are relations between local people's average salary and averged review count of local restaurant, however, local individual income level and other financial information barely contribute into the success of local restaurants (as Figure 6 suggests), which means restaurant runners should not focus on select address according to outer factors like average salaries in one specific region, instead, they may should mind their own business and may be only improve the quality of food and service themself will lead them to success in the end."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "[1]\tAbout IRS, https://www.irs.gov/about-irs\n",
    "\n",
    "[2]\tSOI Tax Stats - Individual Income Tax Statistics - 2015 ZIP Code Data (SOI), https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi\n",
    "\n",
    "[3]\tYelp Fusion APIs, https://www.yelp.com/fusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
